{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Backward Feature Selector\n",
    "Sequential backward selection is a greedy search algorithm that tries to reduce the initial feature space to a reduced feature subspace.\n",
    "The motivation for performing this feature reduction is to remove the less important features from the feature space. It will automatically selects a subsets of features that are a better predictors of the target variable. This will results in reducing the complexity and computational performance of the model and more importantly, improves the generalization performance of the model. This is specially helpful for the models that don't support regularization like K-Nearest Neighborhood algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "We start with the full set of available features in the dataset and then sequentially remove the number of features until we reach to a desired number of features.\n",
    "After reducing the number of features, we try every possible combination set of remaining features and then keep the combination that results in the highest score.\n",
    "\n",
    "For example if the initial feature space has 5 features (0,1,2,3,4) and we want to reduce it 4 :\n",
    "\n",
    "Initial feature space: \n",
    "\n",
    "(0,1,2,3,4)\n",
    "\n",
    "Here is the possible combination of 4 features from our initial 5 feature space along with their accuracy:\n",
    "\n",
    "| Combinations | Accuracy |\n",
    "|--------------|----------|\n",
    "| (0,1,2,3)    | 0.93     |\n",
    "| (0,1,2,4)    | 0.92     |\n",
    "| (0,1,3,4)    | 0.85     |\n",
    "| (0,2,3,4)    | 0.95    |\n",
    "| (1,2,3,4)    | 0.88     |\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "We fit the estimator using a training set that only has the selected feature in each combination and calculate the score accuracy. The combination with the highest score is selected as the best features for this reduced subspace. We use this and go to the next step to reduce the features again : \n",
    "So, from the previous step (0,2,3,4) had the highest score :\n",
    "\n",
    "Initial feature set: \n",
    "(0,2,3,4) \n",
    "\n",
    "\n",
    "Here is the possible combination of 3 features from our initial 4 feature space along with their accuracy:\n",
    "\n",
    "| Combinations | Accuracy |\n",
    "|--------------|----------|\n",
    "| (0,2,3)      | 0.95     |\n",
    "| (0,2,4)      | 0.94     |\n",
    "| (0,3,4)      | 0.97     |\n",
    "| (2,3,4)      | 0.96     |\n",
    "\n",
    "\n",
    "We can see that the accuracy (cross validation) has increased in our reduced subspace which could be due to the reduction in the over-fitting.\n",
    "\n",
    "Let's see all of this in action by running the model on an actual dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sat May 9 11:35:12 2020\n",
    "@author: Mahmood Khordoo\n",
    "https://github.com/khordoo\n",
    "\"\"\"\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "class SequentialBackwardSelector:\n",
    "    \"\"\"\n",
    "    Sequential backward selector for Scikit-learn estimators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimator, reduced_feature_size=1, use_cross_val=True):\n",
    "        self.estimator = estimator\n",
    "        self.use_cross_val = use_cross_val\n",
    "        self.reduced_feature_size = reduced_feature_size\n",
    "        self.best_features_ = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Finds a reduced set of features that results in the highest accuracy.\n",
    "        Sequentially removes the available features, evaluates the model\n",
    "        accuracy the all the possible combinations\n",
    "        of the reduced feature subspace and keeps the best(highest accuracy)\n",
    "        combination of features for each reduced feature size.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Numpy array\n",
    "        y : Numpy array\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "         None\n",
    "        \"\"\"\n",
    "\n",
    "        feature_size = X.shape[1]\n",
    "        keep_features = range(feature_size)\n",
    "\n",
    "        while feature_size >= self.reduced_feature_size:\n",
    "            best_feature_combination = None\n",
    "            best_score = 0\n",
    "\n",
    "            for feature_combination in combinations(keep_features, feature_size):\n",
    "                score = self._score(X, y, feature_combination)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_feature_combination = feature_combination\n",
    "\n",
    "            keep_features = best_feature_combination\n",
    "            self._save_score(feature_size, best_score, best_feature_combination)\n",
    "            feature_size -= 1\n",
    "\n",
    "    def _score(self, X, y, selected_feature_indexes):\n",
    "        if self.use_cross_val:\n",
    "            score = cross_val_score(self.estimator, X[:, selected_feature_indexes], y).mean()\n",
    "        else:\n",
    "            self.estimator.fit(X[:, selected_feature_indexes], y)\n",
    "            score = self.estimator.score(X[:, selected_feature_indexes], y)\n",
    "        return score\n",
    "\n",
    "    def _save_score(self, num_features, best_score, best_feature_combination):\n",
    "        self.best_features_.append({\n",
    "            'featureSize': num_features,\n",
    "            'score': best_score,\n",
    "            'features': best_feature_combination\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Here we are gonna try this on the wines dataset that initially has 13 features. We are going to fit an unregulated estimator , KNearestNeighbourhood from sklearn. Due to a high number of features and relatively small number of samples 178, there is a high change that the model would overfit. We will then try to sue Sequential Backward selection to find the best possible subset of features that result in higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "We load the data from the UCI machine learning repository (https://archive.ics.uci.edu/ml/datasets/Wine);\n",
    "it has 178 examples with 13 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class label</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0            1    14.23        1.71  2.43               15.6        127   \n",
       "1            1    13.20        1.78  2.14               11.2        100   \n",
       "2            1    13.16        2.36  2.67               18.6        101   \n",
       "3            1    14.37        1.95  2.50               16.8        113   \n",
       "4            1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "'https://archive.ics.uci.edu/ml/'\n",
    "'machine-learning-databases/wine/wine.data',\n",
    "header=None)\n",
    "df.columns = ['Class label', 'Alcohol',\n",
    "'Malic acid', 'Ash',\n",
    "'Alcalinity of ash', 'Magnesium',\n",
    " 'Total phenols', 'Flavanoids',\n",
    " 'Nonflavanoid phenols',\n",
    " 'Proanthocyanins',\n",
    " 'Color intensity', 'Hue',\n",
    " 'OD280/OD315 of diluted wines',\n",
    " 'Proline']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:]\n",
    "y=df.iloc[:,0]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, stratify=y , random_state=2,shuffle=True)\n",
    "sc=StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_s=sc.transform(X_train)\n",
    "X_test_s=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Feature selection\n",
    "Let's reduce the feature space from 13 to 1 and see how the accuracy changes in each reduced feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "knn = KNeighborsClassifier(n_neighbors=10, p=2, n_jobs=4)\n",
    "sbs = SequentialBackwardSelector(estimator=knn, reduced_feature_size=1, use_cross_val=True)\n",
    "sbs.fit(X_train_s, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best_features_ property of the SequnetialBackwardSelector object provides a list of best score and their corresponding feature indexes at each reduced feature subspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'featureSize': 13,\n",
       "  'score': 0.959920634920635,\n",
       "  'features': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)},\n",
       " {'featureSize': 12,\n",
       "  'score': 0.9678571428571429,\n",
       "  'features': (0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12)},\n",
       " {'featureSize': 11,\n",
       "  'score': 0.9837301587301588,\n",
       "  'features': (0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 12)},\n",
       " {'featureSize': 10,\n",
       "  'score': 0.9841269841269842,\n",
       "  'features': (0, 1, 2, 3, 5, 6, 7, 9, 11, 12)},\n",
       " {'featureSize': 9,\n",
       "  'score': 0.9841269841269842,\n",
       "  'features': (0, 1, 2, 3, 5, 7, 9, 11, 12)},\n",
       " {'featureSize': 8,\n",
       "  'score': 0.9761904761904762,\n",
       "  'features': (0, 1, 2, 3, 5, 7, 9, 11)},\n",
       " {'featureSize': 7,\n",
       "  'score': 0.9761904761904762,\n",
       "  'features': (0, 1, 2, 3, 5, 9, 11)},\n",
       " {'featureSize': 6,\n",
       "  'score': 0.9761904761904762,\n",
       "  'features': (0, 1, 3, 5, 9, 11)},\n",
       " {'featureSize': 5, 'score': 0.9678571428571429, 'features': (0, 3, 5, 9, 11)},\n",
       " {'featureSize': 4, 'score': 0.959920634920635, 'features': (0, 3, 9, 11)},\n",
       " {'featureSize': 3, 'score': 0.9511904761904763, 'features': (0, 9, 11)},\n",
       " {'featureSize': 2, 'score': 0.9194444444444444, 'features': (0, 11)},\n",
       " {'featureSize': 1, 'score': 0.7178571428571429, 'features': (0,)}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbs.best_features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results\n",
    "Plotting the results shows that the accuracy has indeed increased by reducing the feature space. This shows that the model were previously suffering from the overfitting and by removing the redundant features we have increased the cross-validation accuracy and generalization performance of the model.\n",
    "We can see that 6 features gives us the highest validation accuracy. Lets try to we what score we can get from over test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13722f310>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Just creating two arrays from a dictionariy items\n",
    "num_features, scores = zip(*list(map(lambda x: [x['featureSize'], x['score']], sbs.best_features_)))\n",
    "plt.title('Variation of model accuracy vs number of features)')\n",
    "plt.xlabel('Feature size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(num_features, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we were able to increase the training accuracy of our model from 0.95 to 0.992 and test accuracy from  to 0.98 . We achieved the higher accuracy despite using  half of the initial available features. This shows that we have reduced the overfitting and have increased the generalization performance of our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
